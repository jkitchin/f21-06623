# -*- coding: utf-8 -*-
"""18_linear_regression_coding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14reYwKijtE4-LZGAy_0uYZETnZSmT2lE

# MCQs
"""

from .MCQs import *

"""# Coding"""

# Commented out IPython magic to ensure Python compatibility.
from IPython.display import display, Markdown
from IPython.core.magic import register_cell_magic
from IPython.core.getipython import get_ipython

import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
from scipy.optimize import minimize

"""## Supporting Functions"""

def strip_magic(line, cell):
    lines = cell.split('\n')
    stripped_lines = [line for line in lines if not line.strip().startswith('%')]

    if(len(lines)>len(stripped_lines)):
        print('Warning: The % magic does not work in this cell.')

    return ('\n'.join(stripped_lines))

def create_new_cell(contents):

    shell = get_ipython()
    shell.set_next_input(contents, replace=False)

def within(x, y):
    return np.allclose(x, y)

"""## Q1

Magic
"""

@register_cell_magic
def L18Q1(line, cell):

    # correct answer
    def correct():

        x = np.array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
        y = np.array([1.72345514, 1.18175921, 1.05747337, 0.92374433, 0.99282016,
        0.98470289, 0.99677186, 0.96897502, 0.99793225, 0.97618342])

        X = np.column_stack([x**0, x, x**2, x**3])
        b = np.linalg.solve(X.T @ X, X.T @ y)

        SStotal = np.sum((y - np.mean(y))**2)
        SSerror = np.sum((y - X @ b.T)**2)
        Rsquared = 1 - SSerror / SStotal

        return Rsquared

    globals = dict()
    exec(strip_magic(line, cell), globals)

    RSQ = globals.get('rsquared', None)

    if RSQ is None:
        print('Looks like you have changed the "rsquared" variable. Use the original template variables.')
        return

    if within(RSQ, correct()):
        print('Correct')
    else:
        print('Incorrect')

"""Question"""

def Code1():

    display(Markdown("""Find the parameters for the equation $y = b_0 + b_1x + b_2x^2 + b_3x^3$
    using the normal equation approach, when fitted to the data given below.
    Also find the R-squared value. Is it a good R-squared value? Does it tell whether we have a good model?"""))

    c = """%%L18Q1
# import the required packages


# given data
x = array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
y = array([1.72345514, 1.18175921, 1.05747337, 0.92374433, 0.99282016,
    0.98470289, 0.99677186, 0.96897502, 0.99793225, 0.97618342])

# find the parameters of the given model



# find the R-squared values
rsquared =

"""

    create_new_cell(c)

# Code1()

print('Code1() imported')

"""## Q2

Magic
"""

@register_cell_magic
def L18Q2(line, cell):

    # correct answer
    def correct():

        x = np.array([-3.   , -2.684, -2.368, -2.053, -1.737, -1.421, -1.105, -0.789,
        -0.474, -0.158,  0.158,  0.474,  0.789,  1.105,  1.421,  1.737,
         2.053,  2.368,  2.684,  3.   ])
        y = np.array([10.221,  7.04 ,  8.025,  4.087,  4.071,  4.011,  1.767,  2.327,
            1.318,  0.86 ,  0.429,  2.122,  1.444,  2.523,  2.187,  3.667,
            5.789,  7.538,  7.449, 10.322])

        # standardizing
        # 10th order polynomial
        X = np.array([x, x**2, x**3, x**4, x**5, x**6, x**7, x**8, x**9, x**10]).T
        xmean = X.mean(axis=0)  # average of every column
        xstd = X.std(axis=0)

        Z = (X - xmean) / xstd

        ymean = y.mean()
        ystd = y.std()

#         Y = (y - ymean) / ystd

        def objective(pars, l):
            SSE = np.sum(np.square(y - ((Z @ pars) * ystd + ymean)))
            return SSE + l * np.sum(np.abs(pars))

        lam = [0.001, 10]
        for L in lam:
            sol = minimize(objective, np.ones(len(Z[0])), (L), method='slsqp')
            plt.plot(x, (Z @ sol.x) * ystd + ymean, '--', label = f'Correct $\lambda$:{L}')

        plt.legend()

        return

    globals = dict()
    exec(strip_magic(line, cell), globals)

    correct()

"""Question"""

def Code2():

    display(Markdown("""Using Lasso regression fit a 10th order polynomial (without intercept) to the data given in the below cell.
    Try 2 different values of $\lambda$: 0.001 and 10. Plot the fitted function for both these values on the same graph.
    Use scipy.minimize ('slsqp' solver) for finding the parameters."""))

    c = """%%L18Q2
# import the required packages


# Data
x = array([-3.   , -2.684, -2.368, -2.053, -1.737, -1.421, -1.105, -0.789,
    -0.474, -0.158,  0.158,  0.474,  0.789,  1.105,  1.421,  1.737,
    2.053,  2.368,  2.684,  3.   ])
y = np.array([10.221,  7.04 ,  8.025,  4.087,  4.071,  4.011,  1.767,  2.327,
    1.318,  0.86 ,  0.429,  2.122,  1.444,  2.523,  2.187,  3.667,
    5.789,  7.538,  7.449, 10.322])

# input
X = np.array([x, x**2, x**3, x**4, x**5, x**6, x**7, x**8, x**9, x**10]).T

# standardize



# define the objective function for minimize with lasso regression
def objective():

    return

# solve the problem using minimize for both the values of lambda and plot

"""

    create_new_cell(c)

# Code2()

print('Code2() imported')
