# -*- coding: utf-8 -*-
"""23_gp_coding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rxwUo7R4UnHQqleW2xUVw3Vr8zJAAeP1

# MCQs
"""

from .MCQs import *

"""# Coding"""

# Commented out IPython magic to ensure Python compatibility.
from IPython.display import display, Markdown
from IPython.core.magic import register_cell_magic
from IPython.core.getipython import get_ipython

import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt

"""## Supporting Functions"""

def strip_magic(line, cell):
    lines = cell.split('\n')
    stripped_lines = [line for line in lines if not line.strip().startswith('%')]

    if(len(lines)>len(stripped_lines)):
        print('Warning: The % magic does not work in this cell.')

    return ('\n'.join(stripped_lines))

def create_new_cell(contents):

    shell = get_ipython()
    shell.set_next_input(contents, replace=False)

def within(x, y):
    return np.allclose(x, y)

"""## Q1

Magic
"""

@register_cell_magic
def L23Q1(line, cell):

    # correct answer
    def correct():

        # training data
        np.random.seed(3)
        X= np.linspace(1, 3, 20)
        Y = np.sin(X) * np.random.normal(1.0, 0.2, len(X))

        # test data
        xp = np.linspace(1.0, 3.0)

        # hyperparameters
        lengthscale = [0.05, 10.0]
        sigma_n = 0.01
        sigma_f = 1

        # for plotting
        colors = ['red', 'blue']
        i = 0

        # run the gpr model and plot
        for lam in lengthscale:

            K1 = sigma_f * np.exp(-(X[None, :] - X[:, None])**2 / (2 * lam**2)) + sigma_n**2 * np.eye(len(Y))
            Kp = sigma_f * np.exp(-(X[None, :] - xp[:, None])**2 / (2 * lam**2))

            yp = Kp @ np.linalg.inv(K1) @ Y

            line, = plt.plot(xp, yp, '--', label = f'$\lambda$:{lam} correct')
            line.set_color(colors[i])
            i+=1

        plt.plot(X, Y, 'k.', label = 'Data')
        plt.legend()

        return

    globals = dict()
    exec(strip_magic(line, cell), globals)

    correct()

"""Question"""

def Code1():

    display(Markdown("""Fit a gaussian process regression model to the data given in the below template for the following two lengthscale values: lengthscale = 0.05, 10.0. Plot the predicted models for the corresponding lengthscales on the same graph.

Given: kernel: RBF, sigma_f = 1.0, sigma_n = 0.01, Test data points: xp = np.linspace(1.0, 3.0)."""))

    c = """%%L23Q1
# import the required packages


# training data
np.random.seed(3)
X = np.linspace(1, 3, 20)
Y = np.sin(X) * np.random.normal(1.0, 0.2, len(X))

# test data
xp = np.linspace(1.0, 3.0)

# hyperparameters
lengthscale = [0.05, 10.0]
sigma_n = 0.01
sigma_f = 1

# run the gpr model and plot

"""

    create_new_cell(c)

# Code1()

print('Code1() imported')

"""## Q2

Magic
"""

@register_cell_magic
def L23Q2(line, cell):

    # correct answer
    def correct(ax1, ax2):

        # data
        np.random.seed(3)
        X = np.linspace(0, 10, 5)
        Y = np.sin(X)

        # test data
        xp = np.linspace(-2, 12.0)

        # RBF
        l = 2.0
        sigma_n = 0.01
        sigma_f = 1
        K1r = sigma_f * np.exp(-(X[None, :] - X[:, None])**2 / (2 * l**2)) + sigma_n**2 * np.eye(len(Y))
        Kpr = sigma_f * np.exp(-(X[None, :] - xp[:, None])**2 / (2 * l**2))
        ypr = Kpr @ np.linalg.inv(K1r) @ Y
        Ktr = sigma_f * np.exp(-(xp[None, :] - xp[:, None])**2 / (2 * l**2))
        sigmar = np.sqrt(np.diag(Ktr - Kpr @ np.linalg.inv(K1r) @ Kpr.T))

        # Linear
        sb, sv, c = 0.5, -0.5, 1.0
        sigma_n = 2.0
        K1l = sb**2 + sv**2 * (X - c)[:, None] * (X - c)[None, :] + sigma_n**2 * np.eye(len(Y))
        Kpl = sb**2 + sv**2 * (xp - c)[:, None] * (X - c)[None, :]
        ypl = Kpl @ np.linalg.inv(K1l) @ Y
        Ktl = sb**2 + sv**2 * (xp - c)[:, None] * (xp - c)[None, :]
        sigmal = np.sqrt(np.diag(Ktl - Kpl @ np.linalg.inv(K1l) @ Kpl.T))

        # plot
        ax1.plot(X, Y, 'k.', label = 'Data')
        ax1.plot(xp, ypr.flatten(), 'r--', label = 'Correct mean')
        ax1.fill_between(xp, ypr + 2*sigmar, ypr - 2*sigmar, alpha=0.2, color='gray', hatch = 'x', label = 'Correct $\sigma$')
        ax1.legend()

        ax2.plot(X, Y, 'k.', label = 'Data')
        ax2.plot(xp, ypl.flatten(), 'r--', label = 'Correct mean')
        ax2.fill_between(xp, ypl + 2*sigmal, ypl - 2*sigmal, alpha=0.2, color='gray', hatch = 'x', label = 'Correct $\sigma$')
        ax2.legend()

        return

    globals = dict()
    exec(strip_magic(line, cell), globals)

    AX1 = globals.get('ax1', None)
    AX2 = globals.get('ax2', None)

    if AX1 is None:
        print('Looks like you have changed the "ax1" variable. Use the original template variables.')
        return
    if AX2 is None:
        print('Looks like you have changed the "ax2" variable. Use the original template variables.')
        return

    correct(AX1, AX2)

"""Question"""

def Code2():

    display(Markdown("""Using gaussian process regression, plot the uncertainty and the predicted model for the data given in the below template.
    Make two separate plots for RBF kernel and Linear kernel. .

    Given: RBF Kernel: lengthscale = 2.0,  sigma_n = 0.01, sigma_f = 1; Linear Kernel: sigma_b = 0.5, sigma_v = -0.5, c = 1.0, sigma_n = 2.0.

    Test data: xp = np.linspace(-2, 12.0).

    Note: Do not change the plot variables in the template and simply build-up upon the given code."""))

    c = """%%L23Q2
# import the required packages


# data
np.random.seed(3)
X = np.linspace(0, 10, 5)
Y = np.sin(X)

# test data
xp = np.linspace(-2, 12.0)

# RBF Kernel GPR



# RBF Kernel plot
plt.figure()
ax1 = plt.axes()
ax1.plot()     # plot the predicted model
ax1.fill_between(, alpha=0.2, color='gray') # plot the uncertainty
ax1.legend()


# Linear Kernel GPR



# Linear Kernel plot
plt.figure()
ax2 = plt.axes()
ax2.plot()     # plot the predicted model
ax2.fill_between(, alpha=0.2, color='gray') # plot the uncertainty
ax2.legend()
"""

    create_new_cell(c)

# Code2()

print('Code2() imported')
